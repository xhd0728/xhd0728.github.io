---
title: "[LREC-COLING 2024] MMAD: Multi-modal Movie Audio Description"
collection: publications
permalink: /publication/2023-10-21-lrec-coling-2024
date: 2023-10-21
paperurl: '#'
---

Abstract
---

Movie Audio Description (AD) aims to generate narrations describing visual elements in movies to aid the visually impaired in following film narratives. Current solutions rely heavily on manual work, resulting in high costs and limited scalability. We propose MMAD, a novel automated pipeline for precise AD generation. MMAD introduces ambient music alongside visual and linguistic, enhancing the model’s multi-modal representation learning through modality encoders and alignment. Besides, a character recognition module leverages pedestrian re-identification and facial recognition to furnish prompts indicating active figures, ensuring contextual and character-centric descriptions. Experiments demonstrate MMAD’s superiority over existing methods, achieving state-of-the-art performances across automated AD generation tasks on film datasets. The proposed model efficiently integrates multimodal signals through specialized encoders and cross-modal projection layers. By capturing nuanced information from diverse inputs, the MMAD framework generates accurate and engaging audio narrations to benefit the visually impaired and enhance their cinematic experiences.
